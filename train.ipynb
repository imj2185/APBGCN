{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fn\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from data.dataset3 import SkeletonDataset\n",
    "from models.net import DualGraphEncoder\n",
    "from optimizer import get_std_opt\n",
    "from utils import make_checkpoint, load_checkpoint\n",
    "from tqdm import tqdm, trange\n",
    "from args import make_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data_loader,\n",
    "              model,\n",
    "              loss_compute,\n",
    "              device,\n",
    "              args,\n",
    "              is_train=True,\n",
    "              desc=None,\n",
    "              num_literals=None,\n",
    "              num_clauses=None):\n",
    "    \"\"\"Standard Training and Logging Function\n",
    "    Args:\n",
    "        data_loader: SATDataset\n",
    "        model: nn.Module\n",
    "        loss_compute: function\n",
    "        device: int\n",
    "        is_train: bool\n",
    "        desc: str\n",
    "        args: dict\n",
    "        num_clauses: tensor\n",
    "        num_literals: tensor\n",
    "    \"\"\"\n",
    "    # torch.autograd.set_detect_anomaly(True)\n",
    "    sat_r = []\n",
    "    total_loss = 0\n",
    "    start = time.time()\n",
    "    bs = args.batch_size\n",
    "    for i, batch in tqdm(enumerate(data_loader),\n",
    "                         total=len(data_loader),\n",
    "                         desc=desc):\n",
    "        batch = batch.to(device)\n",
    "        num_lit = num_literals[i * bs: (i + 1) * bs]\n",
    "        num_cls = num_clauses[i * bs: (i + 1) * bs]\n",
    "        # model.encoder.reset()\n",
    "        gr_idx_lit = torch.cat([torch.tensor([i] * num_lit[i]) for i in range(num_lit.size(0))]).to(device)\n",
    "        gr_idx_cls = torch.cat([torch.tensor([i] * num_cls[i]) for i in range(num_cls.size(0))]).to(device)\n",
    "        with torch.set_grad_enabled(is_train):\n",
    "            adj_pos, adj_neg = batch.edge_index_pos, batch.edge_index_neg\n",
    "            xv = model(batch, args)\n",
    "            loss, sm = loss_compute(xv, adj_pos, adj_neg, batch.xc.size(0), gr_idx_cls[: batch.xc.size(0)], is_train)\n",
    "            total_loss += loss\n",
    "        if i == 0:\n",
    "            sat = 100 * (sm // 0.50001).mean().item()\n",
    "            sat_r.append(sat)\n",
    "            print(\"Sat Rate: \", sat, \"%\")\n",
    "    elapsed = time.time() - start\n",
    "    ms = 'average loss' if is_train else 'accuracy '\n",
    "    print(ms + ': {}; average time: {}'.format(total_loss / len(data_loader.dataset),\n",
    "                                               elapsed / len(data_loader.dataset)))\n",
    "\n",
    "    return total_loss, sat_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
